# 概论 #

## 什么是操作系统 ##

### 用户和设计者的角度 ###

- 用户的角度
    1. 虚拟机的观点
        隐藏复杂的细节，进行高度的抽象，扩充
    2. 用户环境的观点
        操作系统是用户与计算机系统进行交互的界面
- 系统设计者的角度
    1. 资源管理的观点
        管理软硬件资源。监控、分配、回收和保护
    2. 作业组织的观点
        协调各个用户的任务作业请求

### 操作系统的定义 ###

> 操作系统是一组控制和管理计算机软件和硬件资源、合理地对各类作业进行调度、以及方便用户使用的程序集合。

## 操作系统的发展 ##

1. 无操作系统
    纸带、人工、无交互能力
2. 单道批处理系统
    监督程序、对一批作业自动处理、内存中只能放一道程序、无交互能力
3. 多道批处理系统
    作业调度程序、内存中的多个作业并发执行、无交互能力
4. 分时操作系统
    同时允许多个用户通过自己的终端以交互方式使用计算机。分时技术。  
    特性 多路性、独立性、及时性、交互性
5. 实时操作系统
    系统能够及时（即时）响应外部事件的请求，在规定的时间内完成对该事件的处理，并控制所有实时任务协调一致地运行。

## 操作系统的特征 ##

1. 并发：最重要的特征、其他特征的前提  
    在多道程序环境下，在一段时间内，有多个任务同时运行
2. 共享
    系统中的资源可供内存中多个并发执行的进程共同使用。  
    共享资源的类型

    - 临界资源：在一段时间内，只允许一个进程访问
    - 非临界资源：在一段时间内，允许多个进程访问

3. 虚拟性
    通过某种技术把一个物理实体变为若干个逻辑上的对应物。
4. 异步性（不确定性）
    在多道程序环境下，程序执行过程的不确定性。

## 操作系统的体系结构 ##

- 无结构
- 模块化
- 分层
- 微内核

# 进程 #

## 定义 ##

一个正在执行中的程序

## 进程的基本特性 ##

1. 动态性：本质特性
    一个正在计算机上执行的程序，存在生命周期
2. 并发性：重要特性
    任何进程都可以同其他进程一起向前推进
3. 独立性
    各进程的地址空间相互独立
4. 异步性
    进程按照各自独立的、不可预知的速度执行
5. 结构性
    进程=PCB+程序段+数据段

## 进程模型 ##

- 就绪状态
    当进程已分配到除CPU以外的所有必要资源后，只要再获得CPU，便可立即执行过程。
- 执行状态
    进程已获得CPU，其程序正在执行。
- 阻塞状态
    正在执行的进程由于发生某事件而暂时无法继续执行时，便放弃处理机而处于暂停状态，把这种暂停状态称为阻塞状态，有时也称为等待状态。
- 新建状态
    OS已经创建了相关的PCB，但是因为资源限制进程还未调入主存。
- 终止状态
    不再具有执行资格，PCB等信息暂时保留
- 就绪/挂起
    进程在外存，只要调入内存并获得CPU即可执行
- 阻塞/挂起
    进程在外存，等待事件

阻塞与挂起的区别

- 阻塞与否：进程是否等待事件
- 挂起与否：进程是否被换出内存

## PCB ##

### PCB的作用 ###

进程控制块：进程的唯一标识

### PCB中的信息 ###

- 进程标识信息
  - 内部标识符
  - 外部标识符
- 处理机状态信息
  - 通用寄存器
  - 指令计数器
  - 程序状态字
  - 用户栈指针
- 进程调度信息
  - 进程状态
  - 进程优先权
  - 其他信息 （执行时间等信息）
- 其他信息
  - 程序和数据的地址
  - 同步和通信机制
  - 资源清单
  - 链接指针

### 组织方式 ###

- 索引方式
    系统根据所有进程的状态建立几张索引表。
- 链接方式
    通过链接指针将PCB块连接起来，形成队列。

      - 单一队列：所有PCB连成一个队列
      - 多级队列：相同状态的PCB块连接成一个队列

## 操作系统内核 ##

> 一些与硬件紧密相关、基本的、公共的、运行频率较高的模块，以及关键性数据结构等常驻内存，便于提高操作系统运行效能的这部分软件，称为操作系统的内核。

内核的功能：资源管理功能、支撑功能

- 资源管理功能

  - 资源管理
  - 存储管理
  - 设备管理

- 支撑功能
  
  - 中断管理
  - 时钟管理
  - 原语管理

## 执行模式 ##

> 为了实现操作系统内核级安全，由硬件提供CPU特权保护方式，称为模式。

分类： 单模式 多模式

双模式：系统、用户模式。

## 进程的创建 ##

1. 分配一个唯一的进程标识
2. 为进程分配空间
3. 初始化PCB
4. 建立链接
5. 建立其他数据结构

## 进程的终止 ##

1. 根据被终止的进程的标识符找到PCB，读出该进程的状态
2. 若该进程为执行状态，则终止其执行，调度下一个就绪程序执行
3. 若该进程有子孙进程，将其所有的子孙进程终止
4. 释放该进程的所有资源
5. 将该进程从所在队列移除，等待其他进程来搜集信息

## 进程切换 ##

1. 保存当前处于运行状态的进程的现场（程序计数器，程序状态字，寄存器内容）到A的PCB中
2. 将进程控制块移到相应的队列
3. 恢复被选择的进程的现场

## 线程 ##

### 为什么要使用线程 ###

进程的两个特点

1. 资源申请及拥有的实体
2. 调度的实体

系统创建、调度、管理进程的代价很大，为了保持系统的并发性，同时降低开销，将进程资源申请与调度执行分开，进程作为资源申请与拥有的单位，线程作为调度的基本单位。

### 线程的基本操作 ###

1. 派生
    当系统创建一个进程时，同时也为该进程派生一个线程，同一个进程中的线程可以再派生其他的线程。
2. 阻塞
    当线程需要等待某事件发生时，他将被阻塞。
3. 解除阻塞
    当线程的阻塞事件发生，其状态转换为就绪，等待调度
4. 结束
    线程执行完毕，释放其私有资源

### 线程的分类 ###

1. 用户级线程
    线程的创建、撤销和切换等操作全部由应用程序完成，操作系统内核不知道线程的存在，仍以进程为调度单位
2. 内核级线程
    线程的创建、撤销和切换等操作由系统内核完成。操作系统以线程为调度单位
3. 混合线程
    线程的创建、撤销、调度和同步等操作在用户级应用程序中完成。多个用户级线程被影射到一个或较少的某些内核级线程


# 进程的调度 #

> 调度是指在一个队列中，按照某种算法，选择一个合适的个体的过程。

## 调度的原则 ##

- 响应时间  
     从用户通过键盘提交一个请求开始，直至系统首次产生响应为止的时间。
- 周转时间  
    从作业被提交给系统开始，到作业完成为止的这段时间间隔，也称为作业周转时间。  
    构成： 在外存等待调度、在内存等待调度、执行、阻塞时间
- 平均周转时间  
    多个作业周转时间的平均值
- 带权周转时间  
    作业的周转时间与系统为它提供服务时间之比
- 平均带权周转时间  
    多个作业带权周转时间的平均值
- 截止时间  
    某任务必须开始执行的最迟时间，必须完成的最迟时间
- 系统吞吐量  
    单位时间内，系统完成的作业数

### 面向用户的原则 ###

- 响应时间短
- 周转时间短
- 满足截止时间

### 面向系统的原则 ###

- 吞吐量大
- 处理器利用率高
- 资源平衡利用
- 公平
- 优先权高的优先调度

## 调度的类型 ##

### 1 ###

- 非剥夺方式（非抢占）
    执行进程只有在执行完毕，或因申请I/O阻塞自己时，才中断其执行，释放处理机。
- 剥夺方式（抢占）

### 2 ###

- 长程调度
    为被调度的进程分配资源，创建进程，加入就绪队列，等待短程调度。  
    选择多少作业？选择哪些作业？
- 短程调度
    也称进程调度，决定就绪队列中的哪个进程获得CPU。
- 中程调度
    对换功能的一部分，内存紧张时选择进程换入或换出。

## 调度算法 ##

### FIFO 先来先服务 ###

> 进程按照请求CPU的顺序使用CPU。

- 非抢占
- 对长进程有利，对CPU繁忙进程有利

### SPF/SJF 短进程优先/段作业优先 ###

> 短进程或短作业优先调度，前提为执行时间预知。

- 非抢占
- 对短进程有利，减小了平均周转时间
- 由于进程的长短难以准确估计，很难做到真正的短进程优先

### RR 时间片轮转 ###

> 每个进程被分配一个时间片，如果在时间片结束时该进程还在运行，则剥夺其CPU并分配给另一个进程，被剥夺CPU的进程则插入到就绪队列末尾，等待下次调度；如果该进程在时间片内阻塞或结束，则立即切换CPU。

- 抢占
- 对短进程、计算型有利
- 对IO型进程不利
- 用于分时系统

每个时间片结束，首先检查新到来的进程加入到队列尾部，然后把当前进程放到队列尾部。然后调度队首的进程。

### 基于优先级的调度算法 ###

- 静态优先级算法
- 动态优先级算法

- 非抢占优先级算法
- 抢占优先级算法

### SRT 剩余时间最短算法 ###

> 在 SPF 基础上增加了剥夺机制

- 抢占
- 拥有最短的平均周转时间

### HRRN 相应比高者优先 ###

> 当前进程执行完毕或需要阻塞时，选择响应比最高的进程投入执行。

相应比 = （等待时间+要求服务时间）/要求服务时间

- 非抢占
- FCFS 和 SJF 的结合, 既照顾了短作业，又考虑了作业到达的先后顺序，不会使长进程长时间得不到服务
- 动态优先权调度算法
- 难以精确得到服务时间

### 基于时间片轮转的反馈调度算法 ###

- 设置多个就绪队列，每个队列赋予不同优先级，第一队列优先级最高，依次递减；各个队列中进程执行的时间片也不相同，优先级越高的队列中，每个进程的时间片就越小。
- 新进程进入时，首先放入第一个队列尾，按FCFS原则排队，如果在一个时间片内完成则退出，否则将该进程调入第二队列，依次类推。
- 仅当第一队列空闲时，调度程序才调度第二队列中的进程，依次类推。如果CPU正在执行第i队列中某进程时有新进程进入较高的队列（第1～(i-1)中的任何一个队列），则新进程抢占当前运行进程，并将当前运行进程放回到第i队列末尾。

- 能较好地满足各种类型用户的需要。
  - 终端型用户  
    能在第一队列的时间片内完成
  - 短作业  
    能在前几个队列的时间片内完成
  - 长作业  
    依次在前n个队列中运行，然后按照时间片轮转的方式运行，不会长时间得不到处理。

### 实时调度算法 ###

- 最早截止时间优先算法 EDF
- 最低松弛度优先调度算法 LLF

# 互斥与同步 #

## 为什么需要同步 ##

- 进程是计算机中独立个体，且有异步性，并发性
- 资源是计算机中的稀缺个体，需要共享
- 进程之间可能需要协作完成任务

## 进程同步的任务 ##

使并发执行的进程能有效地共享资源和相互合作，使程序具有可在现性

## 临界资源 Critical Resource ##

> 必须互斥使用的资源成为临界资源

## 临界区  Critical Section ##

> 访问临界资源的那段代码

## 临界区使用原则 ###

1. **空闲让进** 如果临界区空闲，则有进程申请就立即进入
2. **忙则等待** 每次只允许一个进程处于临界区
3. **有限等待** 保证进程在有限的时间内能进入临界区
4. **让权等待** 进程在临界区不能长时间阻塞等待某件事情

## 互斥与同步的解决策略 ##

### 软件方法 ###

1. 初步设想 轮换使用临界区

    ```c
        int trun = 0;

        进程 P0
        do{
            while(turn != 0);
            P0 的临界区代码;
            turn = 1;
            P0 的其他代码；
        } while(true);

        进程P1
        do {
            while (turn != 1) ;
            进程P1的临界区代码;
            turn = 0;
            进程P1的其它代码
        } while (true);
    ```

    实现了互斥访问，但违反了空闲让进

2. 设置临界区状态标志

    ```c
    bool flag[2] = {false,false};

    进程P0
    do {
        while (flag[1]) ;               //进入区
        flag[0] = true;                 //进入区
        进程P0的临界区代码； //临界区
        flag[0] = false;                 //退出区
        进程P0的其它代码          //剩余区
    } while (true);

    进程P1
    do {
        while (flag[0]) ;                //进入区
        flag[1] = true;                  //进入区
        进程P1的临界区代码； //临界区
        flag[1] = false;                 //退出区
        进程P1的其它代码          //剩余区
    } while (true);
    ```

    违反了“忙则等待”原则，互斥访问未实现  

3. 预先表明进入临界区  

    ```c
    bool flag[2] = {false,false};

    进程P0
    do {
        flag[0] = true ;
        while (flag[1]);               //进入区
        进程P0的临界区代码； //临界区
        flag[0] = false;                 //退出区
        进程P0的其它代码          //剩余区
    } while (true);

    进程P1
    do {
        flag[1] = true;                  //进入区
        while (flag[0]) ;                //进入区
        进程P1的临界区代码； //临界区
        flag[1] = false;                 //退出区
        进程P1的其它代码          //剩余区
    } while (true)
    ```

    实现了互斥访问。违反了“空闲让进”原则，可能导致死锁。  

4. 预先表明进入临界区 + 谦让

    ```c
    bool flag[2] = {false,false};

    进程P0

    do {
        flag[0] = true;
        while (flag[1])  {
            flag[0] = false;
            <随机延迟一小段时间>；
            flag[0] = true;
        }
        进程P0的临界区代码； //临界区
        flag[0] = false;                 //退出区
        进程P0的其它代码          //剩余区
    } while (true);

    进程P1
    do {
        flag[1] = true;
        while (flag[0]) {
            flag[1] = false;
            <随机延迟一小段时间>；
            flag[1] = true;
        }
        进程P1的临界区代码； //临界区
        flag[1] = false;                 //退出区
        进程P1的其它代码          //剩余区
    } while (true);
    ```

    实现了互斥访问，不会死锁，但可能长时间僵持  

5. Dokker 互斥算法

    ```c
    bool flag[2] = {false,false};
    int tern = 1;
    进程P0
    do {
        flag[0] = true;                            //进入区
        while (flag[1]) {
        if (turn == 1)  {
            flag[0] = false;
            while  (turn == 1) ;
            flag[0] = true;
            }
        }                                                  //进入区
        进程P0的临界区代码；           //临界区
        turn = 1;
        flag[0] = false;                            //退出区
        进程P0的其它代码                   //剩余区
    } while (true)

    进程P1
    do {
        flag[1] = true;                            //进入区
        while (flag[0]) {
        if (turn == 0)  {
            flag[1] = false;
            while  (turn == 0) ;
            flag[1] = true;
            }
        }                                                  //进入区
        进程P1的临界区代码；           //临界区
        turn = 0;
        flag[1] = false;                            //退出区
        进程P1的其它代码                   //剩余区
    } while (true)
    ```

6. Peterson 算法

    ```c
    boolean flag[2] = {false, false};                         //共享的全局变量
    int turn;                                                              //共享的全局变量
    进程P0
    do {
        flag[0] = true;                           //进入区
        turn = 1;                                    //进入区
        while (flag[1] && turn == 1) ; //进入区
        进程P0的临界区代码；           //临界区
        flag[0] = false;                 //退出区
        进程P0的其它代码          //剩余区
    } while (true)

    进程P1
    do {
        flag[1] = true;                           //进入区
        turn = 0;                                    //进入区
        while (flag[0] && turn == 0) ; //进入区
        进程P1的临界区代码；           //临界区
        falg[1] = false;                           //退出区
        进程P1的其它代码                   //剩余区
    } while (true)
    ```

软件方法的特点：

- 软件方法始终不能解决“忙等”现象，降低系统效率。
- 采用软件方法实现进程互斥使用临界资源是很困难的，它们通常能实现两个进程的互斥，很难控制多个进程的互斥。
- 算法设计需要非常小心，否则可能出现死锁，或互斥失败等严重问题。

### 硬件方法 ###

1. **屏蔽中断**  

    ```c
    while (true ) {
            disable interrupt    //屏蔽中断
            critical section          //临界区
            enable interrupt       //启用中断
            remainder                //其余部分
    }
    ```
    进程切换依赖中断实现，如果屏蔽中断，则不会发生进程切换  
    屏蔽中断的特点：

    - 系统无法相应外部请求
    - 无法处理故障
    - 降低性能
    - 不支持多处理器
    - 忙等

2. **专用机器指令**

    一些机器指令保证两个动作的原子性，如在一个指令周期中对一个存储单元读和写。这些动作在一个指令周期中执行，不会被打断。

    **Test and Set 指令**

    ```pascal
    1: function testset(var i:integer) : boolean ;
    2: begin
    3:   if i = 0 then
    4:     begin
    5:       i := 1;
    6:       testset := true;
    7:     end
    8:   else testset := false;
    9: end

    repeat { do no-op } until testset(bolt); {* 当bolt为0时，进入临界区*}
    <critical section>;
    bolt := 0;
    <remainder>;
    ```

    **Exchange 指令**
    ```pascal
    1: procedure exchange(var r: register; var m: memory);
    2:   var temp;
    3:   begin
    4:     temp := m;
    5:     m := r;
    6:     r := temp;
    7:   end

    key := 1;
    repeat exchange(key, bolt) until key=0;
    <critical section>;
    exchange(key，bolt);
    ```

    机器指令方法的有点：
    - 简单易于证明
    - 支持多处理机共享内存的互斥

    缺点：
    - 忙等
    - 死锁
    - 饥饿

### 信号量方法 ###

> 信号量的基本原理是： 两个或多个进程可以通过传递信号进行合作，可以迫使进程在某个位置暂时停止执行（阻塞等待），直到他收到一个可以向前推进的信号（被唤醒）。
> 将实现信号灯作用的变量称为信号量，常定义为记录型变量s，其中一个域为整型，另一个域为队列，其元素为等待该信号量的阻塞进程（通常为FIFO）。

```pascal
type semaphore = record
    count : integer;
    queue : list of process
end;

var s: semaphore;
```

> 信号量的两个原子操作：wait(s)和signal(s)，有时也称作P(s)和V(s)。

```pascal
var s: semaphore;

wait(s):
      s.count  := s.count – 1;
      if s.count < 0
          then  begin
              进程阻塞；
              进程进入s.queue队列；
          end;

signal(s):
      s.count  := s.count + 1;
      if s.count <= 0
          then  begin
              唤醒队首进程；
              将进程从s.queue阻塞队列中移出；
          end;
```

信号量类型：依据使用方式

- 资源信号量：用于申请或归还资源，可以初始化为大于1的正整数，表示系统中某类资源的可用个数。
- 互斥信号量：用于申请或释放资源的使用权，通常初始化为1

## 经典进程同步问题 ##

### **生产者消费者问题 Producer Consumer Problem** ###

问题：

- 生产者和消费者进程共享一个大小固定的缓冲区。
- 一个或多个生产者生产数据，并将生产的数据存入缓冲区。
- 一个或多个消费者从缓冲区中取数据，即消费数据。

生产者/消费者必须互斥

- 生产者和消费者不能同时读/写一个存储单元
- 多个生产者不能同时写缓冲区
- 多个消费者不能同时取缓冲区数据

生产者/消费者必须同步

- 生产者不能向满缓冲区写数据
- 消费者也不能在空缓冲区中取数据

```c
semaphore empty = N
semaphore full = 0
semaphore mutex = 1

Producer:
while (true){
    Produce_a_data();
    P(empty);
    P(mutex);
    Store_the_data();
    V(mutex);
    V(full);
}

Consumer:
while(true){
    P(full);
    P(mutex);
    Get_a_data();
    V(mutex);
    V(empty);
    Consume_the_data();
}
```

*桌子上有一只盘子，最多可以放入N（N>0）个水果。爸爸随机向盘中放入苹果或桔子。儿子只吃盘中的桔子，女儿只吃盘中的苹果。只有盘子中水果数目小于N时，爸爸才可以向盘子中放水果；仅当盘子中有自己需要的水果时，儿子或女儿才可以从盘子中取出相应的水果；每次只能放入或取出一个水果，且不允许多人同时使用盘子。用信号量机制实现爸爸、儿子和女儿之间的同步与互斥活动，并说明所定义信号量的含义。要求用伪代码描述.*

```python
sem orange = 0
sem apple = 0
sem empty = N
sem mutex =1
def father():
    while True:
        fruit = orange or apple
        P(empty)
        P(mutex)
        Put_an_fruit(fruit)
        V(mutex)
        if fruit == apple:
            V(apple)
        else:
            V(orange)
def son():
    while True:
        P(orange)
        P(mutex)
        Get_an_orange()
        V(mutex)
        V(empty)
        Eat_the_orange()
def daughtor():
    ...
```

*桌子上有一只盘子，爸爸负责向盘中放苹果，妈妈负责向盘中放桔子。儿子只吃盘中的桔子，女儿只吃盘中的苹果。只有盘子为空时，爸爸或妈妈才可以向盘子中放入一个水果。仅当盘子中有自己需要的水果时，儿子或女儿才可以从盘子中取出相应的水果。请用信号量机制实现爸爸、妈妈、儿子和女儿之间的同步与互斥活动，并说明所定义信号量的含义。要求用伪代码描述。*

```c
semaphore plate = 1;                         //是否允许向盘子放入水果
semaphore apple = 0, orange = 0;    //盘子中是否有苹果、桔子
dad() {
    while (true) {
         prepare an apple;
         P(plate);                               //互斥向盘子放水果
         put an apple on the plate;  //将苹果放入盘中
         V(apple);                             //允许取苹果
    }
}
mom() {
    while (true) {
         prepare an orange;
         P(plate);                                 //互斥向盘子放水果
         put an orange on the plate;  //将桔子放入盘中
         V(orange);                              //允许取桔子
    }
}
son()
{
    while (true) {
         P(orange);                                    //互斥取水果
         get an orange from the plate;     //从盘中取出桔子
         V(plate);                                       //允许向盘中放入水果
    }
}

daughter()
{
    while (true) {
         P(apple);                                      //互斥取水果
         get an apple from the plate;       //从盘中取出苹果
         V(plate);                                       //允许向盘中放入水果
    }
}
```

### **读者写着问题** ###

- 允许多个读者进程可以同时读数据；
- 不允许多个写者进程同时写数据，即只能互斥写数据；
- 若有写者进程正在写数据，则不允许读者进程读数据——互斥读写。

**读者优先**

> 一旦有读者正在读数据，则允许随后的读者进入读数据。
> 只有当全部读者退出，才允许写者进入写数据。
> 导致写者饥饿

```c
int readcount = 0
semaphore mutex = 1
semaphore wsen = 1

reader():
while (true){
    P(mutex);
    readcount += 1;
    if (readcount == 1)
        P(wsem);
    V(mutex);

    do_read();

    P(mutex);
    readcount -= 1;
    if (readcount == 0)
        V(wsem);
    V(mutex);
}

Writer():
while (true){
    P(wsem)
    do_write();
    V(wsem)
}
```

**公平优先**

> 读者、写者的执行顺序与到达顺序严格一致

```c
int readcount = 0
semaphore mutex = 1
semaphore wsem = 1
semaphore wrsem = 1

reader():
while (true){
    P(wrsem);
    P(mutex);
    readcount += 1;
    if (readcount == 1)
        P(wsem);
    V(mutex);
    V(wrsem);

    do_read();

    P(mutex);
    readcount -= 1;
    if (readcount == 0)
        V(wsem);
    V(mutex);
}

Writer():
while (true){
    P(wrsem);
    P(wsem);
    do_write();
    V(wsem);
    V(wrsem);
}
```

**写者优先**

> 只要有一个写者申请写数据，则不再允许新的读者进入读数据。

```c
int readcount = 0
semaphore rcmutex = 1
int writecount = 0
semaphore wcmutex = 1

semaphore rsem = 1
semaphore wsem = 1

reader():
while (true){
    P(rsem);
    P(rcmutex);
    readcount += 1;
    if (readcount == 1)
        P(wsem);
    V(rcmutex);
    V(rsem);

    do_read();

    P(rcmutex);
    readcount -= 1;
    if (readcount == 0)
        V(wsem);
    V(rcmutex);
}

Writer():
while (true){
    P(wcmutex);
    writecount += 1;
    if (writecount == 1)
        P(rsem);
    V(wcmutex);

    P(wsem)
    do_write();
    V(wsem)

    P(wcmutex);
    writecount -= 1;
    if (writecount == 0)
        V(rsem);
    V(wcmutex);
}
```

# 死锁 #

> 多个进程因为竞争资源或执行时推进的顺序不当，或相互通信出现永久阻塞现象

## 产生的原因 ##

- 资源不足导致的资源竞争
- 并发执行的顺序不当

## 资源的分类 ##

- 可剥夺性资源、非剥夺性资源  
    竞争非剥夺性资源可能会导致死锁
- 可重用资源、可消耗资源
    竞争可消耗资源可能导致死锁

## 死锁产生的条件 ##

- 互斥
- 占有且等待
- 非剥夺
- 循环等待

互斥、占有且等待、非剥夺条件是死锁产生的必要条件，但不是充分条件。  
只要系统出现循环等待，则一定出现死锁。

## 解决死锁的方法 ##

### 预防死锁 ###

> 在申请资源时，添加限制条件，以此来破坏产生死锁的条件。

- 破坏互斥条件  
    不能行
- 破坏占有且等待条件  
    进程开始运行前一次性地申请全部资源
- 破坏非抢占条件  
    一个已经保持了某些资源的进程, 当它再提出新的资源请求而不能立即得到满足时, 必须释放它已经保持的所有资源, 待以后需要时再重新申请。
- 破坏环路等待条件
    进程请求资源必须严格按照资源序号的顺序。

### 避免死锁 ###

> 不需事先采取限制措施破坏产生死锁的必要条件。在系统运行过程中，对进程发出的每一个资源申请进行检查，并根据检查结果决定是否分配资源。若分配后系统可能发生死锁，则不予分配（阻塞），否则予以分配——动态检查。

安全序列：一个进程序列是安全的，如果对于每一个进程，它以后尚需要的资源量不超过系统当前剩余资源量与前面的进程当前占有的资源量的总和。

安全状态：存在安全序列的状态。

存在安全序列 -> 无死锁。  
死锁 -> 不安全状态。  
并非所有的不安全状态都是死锁状态。

#### 方法： 银行家算法 ####

### 检测死锁并解除死锁 ###

> 允许死锁出现，然后再解除它。

#### 检测死锁：资源分配图 ####

状态S为死锁状态的充要条件是：当且仅当S状态的资源分配图是不可完全简化的。

#### 解除死锁 ####

- 撤销进程
- 剥夺资源
- 进程回退

#### 忽略死锁 ####

### 哲学家就餐问题 ###

资源分级  
    为资源（这里是餐叉）分配一个偏序（partial order）或者分级（hierarchy）的关系，并约定所有资源都按照这种顺序获取，按相反顺序释放，而且保证不会有两个无关资源同时被同一项工作所需要。

1. 为哲学家编号  

    - 奇数号的哲学家必须首先拿左边的餐叉
    - 偶数号的哲学家必须首先拿右边的餐叉

2. 为餐叉编号

    - 就餐前，先取用编号较低的餐叉，再取用编号较高的餐叉；
    - 就餐毕，先放下编号较高的餐叉，再放下编号较低的餐叉。

    ```c
        semaphore fork[5] = {1, 1, 1, 1, 1};
        void main()
        {
                cobegin {philosopher(0); philosopher(1); philosopher(2); philosopher(3); philosopher(4);}coend;
        }
        void philosopher(int i)
        {
                while(true) {
                        think();  //思考
                        if (i  !=  4) {
                            wait(fork[i]); wait(fork[(i+1)%5]);} //先左后右
                        else {
                            wait(fork[(i+1)%5]); wait(fork[i]);} //先右后左
                        eat(); 
                        if (i  !=  4) {
                            signal(fork[(i+1)%5]); signal(fork[i]);} //先右后左
                        else {
                            signal(fork[i]); wait(fork[(i+1)%5]);} //先左后右
                }
        }
    ```

3. 服务生方法
    引入一个餐厅服务生，哲学家必须经过他的允许才能拿起餐叉。最多允许4个哲学家同时进食。

# 存储管理 #

## 程序的链接和装入 ##

源代码转化为进程的三个步骤

- 编译：由编译程序将用户源代码编译成若干个目标模块
- 链接：有链接程序将编译后的一组目标模块，以及它们所需要的函数链接在一起，形成一个完整的装入模块。
- 装入：由装入程序将装入模块装入内存，同时进行地址重定位。

空间分类

- 名空间：汇编语言或高级语言用于访问储单元的符号名组成的程序空间
- 逻辑空间：编译后目标程序以0为基址进行编址
- 内存空间（物理空间）：内存由若干个存储单元组成，每个单元的编号称为内存地址。内存地址的集合成为内存空间或物理空间。

地址映射：将逻辑地址转换为运行时由机器直接寻址的物理地址。

### 链接的方式 ###

1. 静态链接  
    在程序运行之前，将各个模块及它们所需的函数库，链接还曾一个完整的装配模块，以后不再拆开。  
    目标模块使用起始地址为0的相对地址，不利于代码共享，浪费存储空间，不利于升级。
2. 装入时动态链接  
    目标模块在装入内存时，采用边装入边链接的方式。  
    有利于模块的共享和升级，但装入后不能移动位置。
3. 运行时动态链接
    执行中需要该模块时，由操作系统去寻找该模块并将其装入内存，随后把它链接到调用模块上。  
    加快装入过程，节省大量存储空间。

### 装入的方式 ###

1. 绝对装入方式  
    程序中的逻辑地址与实际内存地址完全相同，编译器产生绝对地址的目标代码，装入时不需要对地址进行修改。  
    实现简单，无须地址变换，但程序必须装入同一内存区域，不支持多道程序系统。
2. 静态重定位装入方式  
    逻辑地址和装入内存后物理地址没有直接的关系，编译时采用相对地址，允许将程序装入到与逻辑地址不同的物理地址。地址映射在装入时进行，以后不再更改程序地址。  
    易实现，无须硬件支持。但装入后不能移动，不利于内存的有效利用，难于共享。
3. 动态重定位装入方式  
    程序的地址转换不是在装入时进行的，而是在程序运行时动态进行。  
    需要硬件支持。程序可以分散存储，可以移动，便于共享。

## 存储管理方式 ##

### 单一连续分配 ###

> 整个内存空间分成系统区和用户区，系统区给操作系统使用，用户区给用户使用。整个用户区分配给一个进程。

适用于单一用户，单任务OS。易于管理。

### 分区管理 ###

> 把内存分为一些大小相等或不相等的分区。每个应用程序占用一个或多个分区，操作系统占用其中的一个分区。

适用于多道程序和分时系统。  
存在内部碎片和外部碎片，难以共享

#### 固定分区 ####

> 分区的划分由操作系统决定，一旦划分，在整个执行过程中每个分区的长度和分区的总数保持不变

难以进行共享，存在内部碎片

划分方法：

1. 分区大小相等
2. 分区大小不等

小作业的内部碎片比较大，作业必须估计需要占用的内存空间，限制了系统中活跃的进程数目。

#### 动态分区 ####

> 根据进程的实际需要，动态地为之分配内存空间。

空闲分区表：记录每个空闲分区的情况  
空闲分区链：将所有的空闲分区连成一个双向链

##### 动态分区分配算法 #####

|名称|分配方法|优缺点|
|---|---|---|
|首次匹配|空闲分区链以地址递增的次序链接，分配时从链首开始顺序查找，直到找到一个大小能满足要求的空闲分区为止。|每次从头查找，在后端留有较大的分区，可以用来容纳大程序，但是低地址反复划分，形成小碎片|
|循环匹配|和首次匹配类似，但是每次从上次结束的位置开始寻找|分区嗲小均匀，查找开销比较小，缺乏大空间容纳后来的程序|
|最佳匹配|寻找最接近需要大小的空间|分配剩余下的造成浪费|

##### 紧凑与动态重定位 #####

可重定位分区分配:采用动态重定位技术的分区分配。  
紧凑技术：将内存中所有的作业进行移动，使他们都相邻接，可以把分散的空闲小分区合并还曾一个大分区。

##### 存储保护 #####

防止一个作业有意或无意地破坏操作系统或其他作业。

- 上下界寄存器方法
- 基址、限长寄存器方法

动态划分方案使存储管理复杂，紧凑技术需要额外开销。

#### 伙伴系统 ####

速度快、但内存利用率不高，存在内部碎片

### 对换 ###

目标：在较小的可用内存中运行较大的程序

覆盖:一个程序的几个代码段或数据段，按照时间先后来占用公共的内存空间。不需要OS提供支持，需要程序员设计和编写覆盖结构，增加编程的复杂度。

对换：把内存中暂不能运行的进程或者暂不使用的程序和数据换出到外存上，以腾出足够的内存空间，把已具备运行条件的进程或进程所需要的程序和数据换入内存。由操作系统的内存管理模块完成，与程序结构无关。

对换区一般采用连续分配方式。

对换的粒度：

- 整体交换：以进程为单位
- 部分交换：页面、段为单位，支持虚拟存储系统

### 离散分配方式 ###

> 一个进程分配的内存由多个离散的空间组成

逻辑地址、物理地址、地址转换、页表、快表TLB

#### 离散分配方式的分类 ####

- 分页存储管理
    存在内部碎片，但是比较小，内存利用率高，无外部碎片，需要硬件支持，TLB  
    不支持动态链接，不易实现共享
- 分段存储管理
    便于程序模块化设计、便于动态链接和共享、无内部碎片、有外部碎片、需要硬件支持
- 段页式存储管理
    采用分段方法组织用户程序，采用分页方法分配和管理内存。  
    内存利用率高、无外部碎片、便于保护、共享、地址转换复杂

段与页式的比较

|页式|段式|
|---|---|
|信息的物理单位|信息的逻辑单位|
|目的是实现离散分配，减少外部碎片，提高内存的利用率，系统管理的需求|目的是为了满足用户的需求|
|大小固定由系统决定|大小不固定，取决于用户的程序|
|不易实现共享和动态链接|容易实现共享和动态链接|
|地址空间是一维的|地址空间是多维的|

## 虚拟存储器 ##

### 程序运行的特点 ###

- 大多数情况顺序执行
- 调用深度通常不超过5
- 相当多的循环，指令重复执行
- 相当多特定数据结构的操作，局限在较小的范围中

### 局部性原理——虚拟存储器的理论依据 ###

- 时间局部性
- 空间局部性

### 虚拟存储器的概念 ###

具有 **请求调入** 和 **置换功能** 的能从逻辑上拓展存储器容量的存储器。

### 虚拟存储器的特性 ###

- 离散性
- 局部性
- 对换性
- 虚拟性

### 虚拟存储器的分类 ###

#### 请求分页存储管理 ####

> 在基本分页机制上引入 **请求调页** 和 **页面置换** 功能

页表机制：页号、页框号、状态位P、访问位A、修改位M、外存地址

##### 页面分配策略：进程页面的数量是否可以变化 #####

- 固定分配
- 可变分配

##### 置换策略：页面换出选择页面的范围：发生缺页的进程、全部的进程 #####

- 局部置换
- 全局置换

##### 置换算法 #####

- 最优置换算法 OPT  
    换出不再访问或最久不妨问的页面
- 先进先出 FIFO
- 最近最久未使用 LRU
- 时钟置换算法 CLOCK
    每个页面设置一个访问位，访问该页面时置１。所有页面保存在环形链表中。发生缺页中断时，首先检查表针指向页面，如果R为0，则新页面替换之；如果R为1，则清0，表针前移一个位置，重复上述过程。
- 改进的时钟置换算法
    页面分为4类

    1. 1类(A=0, M=0)：最近未被访问，又未被修改，最佳淘汰页。
    2. 2类(A=0, M=1)：最近未被访问，但已被修改页。
    3. 3类(A=1, M=0)：最近已被访问，但未被修改。
    4. 4类(A=1, M=1)：最近已被访问且被修改，最不应淘汰页。

    实现

    1. 选择最佳淘汰页面（A=0，M=0）
    2. 如果1失败，寻找第2类页面（ A=0，M=1 ），并把所扫描过的页面的访问位A置0 。
    3. 如果2失败，回到步骤1。

##### 缺页率： 发生缺页的次数与总访存次数之比 #####

##### 平均访存时间： 缺页率\*缺页时的访存时间+（1-缺页率）\*内存访问时间 #####

##### 进程的工作集：在某段时间内，进程实际要访问的页面的集合 #####

##### 抖动/颠簸 #####

现象：页面频繁地换入换出，缺页率急剧增加。内存存取时间加长，系统吞吐量骤减。

根本原因：多道程序度过高，每个进程分配的页框数过少。

预防的方法

1. 采用局部置换策略
2. 工作集算法
3. L=S准则 发生缺页的平均时间L等于处理缺页故障的平均时长S
4. 挂起若干进程

##### 请求分页存储管理方式的优点 #####

- 存在内部碎片，但相对小，无外部碎片，内存利用率高
- 实现了离散分配
- 虚拟存储器，大作也可以在较小的内存中执行
- 并发度高

##### 请求分页存储管理方式的缺点 #####

- 地址转换、缺页中断、页面淘汰需要硬件支持
- 不支持动态链接和共享
- 多道程序度太高或作业地址空间过大可能会导致颠簸的发生

#### 请求分段存储管理 ####

> 在基本分段机制上引入 **请求调段** 和 **分段置换** 功能

段表：段号、段长、段首址、存取方式、访问位A、修改位M、状态位P、外存地址、增补位

#### 请求段页式存储管理 ####

> 在基本段页式存储管理技术的基础上引入 **请求调页** 和 **页面置换**

##### 段的共享 #####

整个系统有一张共享段表：记录了段本身的信息和引用者的信息

第一次访问共享段：  
    分配内存、增加共享段表项、修改进程段表
后续访问：  
    修改共享段表、修改进程段表

段的保护：越界检查、存取控制检查、环保护机构

# 设备管理 #

## 设备的分类 ##

信息交换单位：块设备、字符设备

使用特征：存储设备、I/O设备

共享属性：独占设备（临界资源）、共享设备、虚拟设备

## I/O 控制方式 ##

1. 程序直接 I/O
2. 中断 I/O
3. DMA 控制方式
4. 通道控制

## 缓冲 ##

缓冲的作用：缓和CPU与I/O设备之间速度不匹配的矛盾

缓冲类型

- 无缓冲
- 单缓冲  
    每块数据处理时间： MAX（T，C）+ M
- 双缓冲  
    每块数据处理时间： MAX（T，C+M）
- 多缓冲

单缓冲和双缓冲：字符设备  
循环缓冲：块设备

### SPOOLing 磁盘中的缓冲 ###

SPOOLing 可以将一台物理的独占I/O设备虚拟为多台逻辑I/O设备，从而允许多个用户共享一台物理I/O设备。

组成：输入井、输出井、输入缓存、输出缓存、输入进程、输出进程

特点：

- 提高I/O速度
- 将独占设备改造为共享设备
- 实现了虚拟设备的功能：将独占设备变为多台对应的逻辑设备

## 设备的两层结构 ##

- 设备硬件无关层：实现设备映射功能，把逻辑设备映射到物理设备
- 设备硬件相关层：实现设备驱动功能，控制物理I/O设备完成实际的I/O操作

设备无关性：

- 应用程序独立于具体使用的物理设备，使用逻辑设备名来请求设备
- 系统执行时使用物理设备名称
- 系统将逻辑设备映射到物理设备： 逻辑设备表 LUT

## 设备分配 ##

分配算法： 先来先服务、优先级高着优先

设备分配的安全性：

- 安全分配方式：进程发出I/O请求后进入阻塞状态，知道I/O完成时才被换醒，破坏了“请求和保持”的死锁条件
- 不安全分配方式

## 磁盘存储器 ##

### 磁盘访问时间 ###

- 寻道时间  
    磁头移动到指定柱面/磁道上所经历的时间
- 传输时间  
    磁头进行读写数据所经历的时间
- 延迟时间  
    指定扇区移动到磁头下所经历的时间

### 磁盘调度算法 ###

1. 先来先服务 FCFS
2. 最短寻道时间优先 SSTF
3. 扫描算法 SCAN
4. 循环扫描算法 CSCAN
5. 扫描算法 LOOK
6. 循环扫描算法 CLOOK
7. NStepSCAN

能缓解磁臂粘着现象的是 FCFS、NStepSCAN、FSCAN

### 提高磁盘I/O速度 ###

磁盘高速缓存（disk cache）：利用内存中的存储空间来暂时存放磁盘中的信息。

# 文件系统 #

## 实现模型 ##

- 文件系统接口
- 逻辑功能层
- 物理驱动层

## 文件的逻辑结构 ##

1. 无结构文件  
    由字符流构成的文件。
2. 堆文件  
    变长记录（例如日志文件）
3. 顺序文件  
    记录长度相同，结构相同，每个记录有一个关键域
4. 索引文件  
    保留顺序文件的关键特征，记录按照关键域有序组织，增加了支持随机访问的文件索引
5. 哈希文件  
    存储位置可以根据关键字段计算出来

## 文件的物理结构 ##

1. 连续结构  
    简单容易实现，连续读写的性能好。不利于动态增长，导致磁盘碎片。
2. 链接结构  
    文件信息存放在若干不连续的物理块中，各块之间通过指针链接。

    - 隐式链接： 每个物理块设有一个指针字段。
    - 显式链接： 用于链接的指针显式地存放在一张表中。

    提高了利用率，有利于动态增长。可靠性问题，随机访问差。
3. 索引结构  
    文件信息存放在若干不连续物理块中，系统为每个文件建立一个索引表，并将这些块的块号存放在一个索引表中。

    单级索引、多级索引

    支持随机存储，满足动态增长，支持大型文件、寻道次数和时间长，索引表开销。

## 目录 ##

### 文件控制块 ###

文件控制块是文件存在的标志

#### FCB的组成 ####

- 基本信息  
    文件名、物理位置、逻辑结构、物理结构
- 存取控制  
    权限
- 使用信息  
    时间戳

### 目录概念 ###

> 文件控制块的有序集合称为 文件目录。文件控制块就是其中的目录项。

由目录项构成的文件为目录文件。

### 目录功能 ###

- 按名存取：最基本的功能
- 提高检索速度
- 文件共享
- 允许重名

### 引索节点 ###

把文件属性信息用一个称为索引节点的数据结构来描述，而在文件目录的每个目录项中，仅存有文件名和该文件的索引节点编号。

### 目录组织方式 ###

- 单极目录
- 两级目录
- 层次目录
    - 树形目录
    - 无循环图结构

### 空闲磁盘块空间管理 ###

- 空闲分区表：空闲分区号、分区起始块号、分区长度
- 空闲分区链
- 位示图 bitmap